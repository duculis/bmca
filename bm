#!/usr/bin/env python
import os
import re
from clize import run
from datetime import datetime
import sqlite3
from bs4 import BeautifulSoup
import requests
from tabulate import tabulate
import pandas as pd
pd.set_option('display.max_colwidth', -1)

db_path = os.path.join(os.getenv('HOME'), '.bm.db')


def a(url, *, desc='', tags=''):
    """
    Add a url to the bookmark database

    desc : description (optional)
    tags : list of tags separated by space (optional)

    Examples:

    bm a "http://github.com/mehdidc/bm"

    bm a "http://github.com/mehdidc/bm" --tags='bm bookmark'

    bm a "http://github/com/mehdidc/bm" --desc='bookmark in command line'
    """
    conn = sqlite3.connect(db_path)
    c = conn.cursor()
    c.execute(
        "CREATE TABLE IF NOT EXISTS urls(id INTEGER primary key,"
        "time TIMESTAMP, url TEXT UNIQUE, title TEXT, "
        "description TEXT, tags TEXT, views INT)")
    time = datetime.now()
    title = _get_title(url)
    title = title.replace("'",  "")
    print('Adding url : {}, title : {}...'.format(url, title))
    q = (
        "INSERT INTO urls VALUES("
        "NULL, '{time}', '{url}', '{title}', "
        "'{desc}', '{tags}', {views})".format(
            time=time,
            url=url,
            title=title,
            desc=desc,
            tags=tags,
            views=0)
    )
    try:
        c.execute(q)
        conn.commit()
    except sqlite3.IntegrityError:
        print('Failed, url "{}" Already exists in the database.'.format(url))


def ls(q='', *, id=-1, tags='', sort_by='views', nb=-1, trim=True, open=False, mode='and'):
    """
    display the list of urls in the bookmark

    q : str
        list of keywords separated by space
        to search for in the urls or titles or tags
    id : int
        specic id of a url to display (optional)
    tags : str
        specify tags separated by space to search for
    sort_by : str
        sort the urls by 'views' or 'id' or 'url' or 'time'
    trim : true or false
        whether to trim long urls or titles
    open : true or false
        whether to open the first url in the diplayed list
        in the browser
    nb : int
        number of rows to display
    Examples:

    bm ls

    bm ls 'deep learning video'

    bm ls --id=142

    bm ls --tags='video'

    bm ls 'deep learning video' --trim=false

    bm ls --id=142 --open
    """
    if trim:
        max_length = 50
    else:
        max_length = float('inf')

    conn = sqlite3.connect(db_path)
    keywords = q.split(' ')
    w = _search_request(keywords, mode=mode)
    if tags != '':
        tags = tags.split(' ')
        wtags = ["tags LIKE '{}'".format(tag) for tag in tags]
        wtags = ' OR '.join(wtags)
        if q == '':
            w = wtags
        else:
            w = "({}) AND ({})".format(w, wtags)

    # update nb of views only when we search for something
    if q != '':
        q = "UPDATE urls SET views = views + 1 WHERE {w}".format(w=w)
        c = conn.cursor()
        c.execute(q)
        conn.commit()

    if id >= 0:
        q = (
            "SELECT id, url, title, views, time FROM urls "
            "WHERE id={}".format(id)
        )
    else:
        q = (
            "SELECT id, url, title, views, time FROM urls WHERE "
            "{w} ORDER BY {sort_by} DESC".format(
                w=w,
                sort_by=sort_by
            )
        )
    c = conn.cursor()
    rows = []
    for row in (c.execute(q)):
        id_, url, title, views, time = row
        if id < 0:
            url = _format(url, max_length=max_length)
            title = _format(title, max_length=max_length)
        rows.append((id_, url, title, views))
    if nb > 0:
        rows = rows[0:nb]
    print(tabulate(rows, headers=['id', 'url', 'title', 'views']))

    if open:
        import webbrowser
        _, url, _, _ = rows[0]
        webbrowser.open(url)


def _format(s, max_length=50):
    s = s.replace('\n', '')
    if len(s) > max_length:
        s = s[0:max_length] + '(...)'
    return s


def rm(q='', *, id=-1, mode='and'):
    """
    remove a list of urls or one url
    from the bookmarks database

    q : str
        list of keywords to search for separated by space
    id : int
        id of a specific url to remove (optional)

    Examples:

    bm rm --id=143

    bm rm 'deep learning video'
    """
    if id < 0:
        keywords = q.split(' ')
        w = _search_request(keywords, mode=mode)
        q = "SELECT * FROM urls WHERE {}".format(w)
    else:
        q = "SELECT * FROM urls WHERE id={}".format(id)
    conn = sqlite3.connect(db_path)
    c = conn.cursor()
    for row in c.execute(q):
        id_, url, *rest = row
        response = ''
        while response not in ('y', 'n'):
            print('Delete {} ? (y/n)'.format(url), end='')
            response = input()
            c.execute("DELETE FROM urls WHERE id={}".format(id_))
    conn.commit()


def export_csv(out):
    """
    export the database into csv

    out : str
        filename where to write the csv

    Examples:

    bm export out.csv
    """
    df = _export_dataframe()
    df.to_csv(out, index=False)


def _export_dataframe(order_by='views'):
    q = "SELECT id, time, url, title, tags, views FROM urls ORDER BY {}".format(order_by)
    conn = sqlite3.connect(db_path)
    c = conn.cursor()
    rows = []
    for row in c.execute(q):
        rows.append(row)
    cols = ['id', 'time', 'url', 'title',  'tags', 'views']
    df = pd.DataFrame(rows, columns=cols)
    return df


def export_html(out, *, order_by='views'):
    df = _export_dataframe(order_by=order_by)
    df['url'] = df['url'].apply(to_link)
    df['time'] = pd.to_datetime(df['time']).apply(to_date)
    df.to_html(
        out, 
        index=False, 
        escape=False,
        col_space=100,
    )



def to_date(time):
    return time.date()


def to_link(url):
    return '<a href="{url}">{url}</a>'.format(url=url)

def tags():
    """
    list of available tags
    """
    q = "SELECT tags FROM urls"
    conn = sqlite3.connect(db_path)
    c = conn.cursor()
    tags = []
    for tag, in c.execute(q):
        tag = tag.split(' ')
        tags.extend(tag)
    tags = sorted(list(set(tags)))
    for t in tags:
        print(t)


def tag(q='', *, id=-1, mode='and'):
    """
    override the tags of urls

    q : str
        keywords to search for separated by space
    id : int
        id of a specific url to tag

    Examples:

    bm tag

    bm tag 'deep learning video'

    bm tag --id=141
    """
    if id < 0:
        keywords = q.split(' ')
        w = _search_request(keywords, mode=mode)
        if q == '':
            q = "SELECT id, url, title FROM urls WHERE tags=''"
        else:
            q = "SELECT id, url, title FROM urls WHERE {}".format(w)
    else:
        q = "SELECT * FROM urls WHERE id={}".format(id)
    conn = sqlite3.connect(db_path)
    c = conn.cursor()
    for id_, url, title in c.execute(q):
        print(url)
        print(title)
        print('New tag ?', end='')
        tag = input()
        if tag != '':
            conn.execute("UPDATE urls SET tags='{}' WHERE id={}".format(
                tag, id_))
            conn.commit()


def reset_views():
    conn = sqlite3.connect(db_path)
    q = "UPDATE urls SET views = 0"
    c = conn.cursor()
    c.execute(q)
    conn.commit()


def _get_title(url):
    """
    get the title of a web page
    """
    soup = BeautifulSoup(requests.get(url).content, 'lxml')
    if soup.title is None:
        return ''
    return soup.title.text


def _search_request(keywords, mode='and'):
    """
    Get the where part of sql query title or url should
    match any of the keywords

    keywords : list of str
    """
    if mode == 'and':
        method = ' AND '
    elif mode == 'or':
        method = ' OR '
    w = method.join([
        "title LIKE '%{q}%' OR url LIKE '%{q}%'".format(q=k) for k in keywords
    ])
    return w

def recommand(*, nb=5, id=-1, open=False):
    from functools import partial
    import numpy as np
    from sklearn.feature_extraction.text import TfidfVectorizer
    df = _export_dataframe()
    titles = _get_active_window_titles()
    similarities_list = []
    df['url_title'] = df.apply(lambda d:'{} {}'.format(d['url'], d['title']), axis=1)
    tfidf = TfidfVectorizer().fit(df['url_title'].values.tolist())
    for i, title in enumerate(titles):
        func = partial(similar, tfidf, title)
        df['sim_{}'.format(i)] = df['title'].apply(partial(similar, tfidf, title))
    df['sim'] = df.filter(like='sim_', axis=1).max(axis=1)
    df = df.sort_values(by='sim', ascending=False)
    df = df.iloc[0:nb]
    df['url_full'] = df['url'].copy()
    df['url'] = df['url'].apply(partial(_format, max_length=100))
    cols = df[['id', 'url', 'sim']].to_dict(orient='list')
    print(tabulate(cols, headers='keys'))
    if open:
        import webbrowser
        if id >=0:
            url = df.set_index('id').loc[id]['url_full']
        else:
            url = df.iloc[0]['url_full']
        webbrowser.open(url)

def _get_active_window_titles():
    from subprocess import check_output
    output = check_output('wmctrl -l', shell=True).decode()
    lines = output.split("\n")
    titles = []
    for line in lines:
        line = line.strip()
        if len(line) == 0:
            continue
        _, state, _, *rest = re.split('[ \t]+', line)
        title = ' '.join(rest)
        if state != "-1":
            if ' - ' in title:
                title, *rest = title.split(' - ')
                titles.append(title)
    return titles


def similar(tfidf, a, b):
    import numpy as np
    x = tfidf.transform([a, b])
    x = np.array(x.todense())
    av = x[0]
    bv = x[1]
    eps = 1e-10
    return np.dot(av, bv) / ((np.linalg.norm(av)+eps) * (np.linalg.norm(bv) + eps))


def _tokenize(s):
    return re.split(r'[ \t\./-]+',  s)

if __name__ == '__main__':
    run([a, ls, rm, export_csv, export_html, tag, reset_views, tags, recommand])
