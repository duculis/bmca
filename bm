#!/usr/bin/env python
import os
import re
from clize import run
from datetime import datetime
import sqlite3
from bs4 import BeautifulSoup
import requests
from tabulate import tabulate
import pandas as pd
from random import randint
pd.set_option('display.max_colwidth', -1)

db_path = os.path.join(os.getenv('HOME'), '.bm.db')


def a(url, *, desc='', tags=''):
    """
    Add a url to the bookmark database

    desc : description (optional)
    tags : list of tags separated by space (optional)

    Examples:

    bm a "http://github.com/mehdidc/bm"

    bm a "http://github.com/mehdidc/bm" --tags='bm bookmark'

    bm a "http://github/com/mehdidc/bm" --desc='bookmark in command line'
    """
    db = sqlite3.connect(db_path)
    db.execute(
        "CREATE TABLE IF NOT EXISTS urls(id INTEGER primary key,"
        "time TIMESTAMP, url TEXT UNIQUE, title TEXT, "
        "description TEXT, tags TEXT, views INT)")
    db.commit()
    time = datetime.now()
    title = _get_title(url)
    title = title.replace("'",  "")
    print('Adding url : {}, title : {}...'.format(url, title))
    query = (
        "INSERT INTO urls VALUES("
        "NULL, '{time}', '{url}', '{title}', "
        "'{desc}', '{tags}', {views})".format(
            time=time,
            url=url,
            title=title,
            desc=desc,
            tags=tags,
            views=0)
    )
    try:
        db.execute(query)
        db.commit()
    except sqlite3.IntegrityError:
        print('Failed, url "{}" Already exists in the database.'.format(url))


def ls(keywords='', *, id=-1, sort_by='time', order='desc', nb=-1, trim=True, random=False, open=False, query_mode='and', fields='all'):
    """
    display the list of urls in the bookmark

    keywords : str
        list of keywords separated by space
        to search for in the urls or titles or tags
    id : int
        specic id of a url to display (optional)
    sort_by : str
        sort the urls by 'views' or 'id' or 'url' or 'time'
    trim : bool
        whether to trim long urls or titles
    random: bool
        whether the result is in random order
    open : true or false
        whether to open the first url in the diplayed list
        in the browser
    nb : int
        number of rows to display
    Examples:

    bm ls

    bm ls 'deep learning video'

    bm ls --id=142

    bm ls --tags='video'

    bm ls 'deep learning video' --trim=false

    bm ls --id=142 --open
    """
    order = order.upper()
    assert order in ('DESC', 'ASC')
    assert query_mode in ('and', 'or')
    assert fields == 'all' or all([f in ('title', 'desc', 'tags', 'url') for f in fields.split(',')])
    max_length = 50 if trim and not random and not open else float('inf')
    db = sqlite3.connect(db_path)
    keywords_list = keywords.split(' ')
    where_request = _build_where_request(
        keywords, 
        query_mode=query_mode, 
        fields=fields
    )
    # update nb of views only when we search for something
    if keywords != '':
        query = "UPDATE urls SET views = views + 1 WHERE {where_request}".format(where_request=where_request)
        db.execute(query)
        db.commit()
    
    # Prepare the search query depending on the situation
    if id >= 0:
        #ID given, show exactly one url
        query = (
            "SELECT id, url, title, views, time FROM urls "
            "WHERE id={}".format(id)
        )
    elif keywords == '':
        #no keyword, return all urls
        query = 'SELECT id, url, title, views, time FROM urls ORDER BY {sort_by} {order}'.format(
            sort_by=sort_by, order=order)
    else:
        #keywords given, look for urls which match the keywords
        query = (
            "SELECT id, url, title, views, time FROM urls WHERE "
            "{where_request} ORDER BY {sort_by} {order}".format(
                where_request=where_request,
                sort_by=sort_by,
                order=order,
            )
        )
    def _format_row(row):
        id, url, title, views, time = row
        url = _format(url, max_length=max_length)
        title = _format(title, max_length=max_length)
        return id, url, title, views
    # Get the results from DB
    rows = db.execute(query)
    rows = map(_format_row, rows)
    rows = list(rows)
    if random:
        idx = randint(0, len(rows))
        rows = rows[idx:idx + 1]
    if nb > 0:
        rows = rows[0:nb]
    print(tabulate(rows, headers=['id', 'url', 'title', 'views']))
    if open:
        import webbrowser
        _, url, _, _ = rows[0]
        webbrowser.open(url)


def _format(s, max_length=50):
    s = s.replace('\n', '')
    if len(s) > max_length:
        s = s[0:max_length] + '(...)'
    return s


def rm(keywords='', *, id=-1, query_mode='and', fields='all'):
    """
    remove a list of urls or one url
    from the bookmarks database

    keywords : str
        list of keywords to search for separated by space
    id : int
        id of a specific url to remove (optional)

    Examples:

    bm rm --id=143

    bm rm 'deep learning video'
    """
    assert (keywords and id==-1) or (id>=0 and not keywords)
    if id == -1:
        keywords_list = keywords.split(' ')
        where_request = _build_where_request(
            keywords_list
            query_mode=query_mode, 
            fields=fields
        )
        query = "SELECT * FROM urls WHERE {}".format(where_request)
    else:
        query = "SELECT * FROM urls WHERE id={}".format(id)
    db = sqlite3.connect(db_path)
    for row in db.execute(query):
        id, url, *rest = row
        response = ''
        while response not in ('y', 'n'):
            print('Delete {} ? (y/n)'.format(url), end='')
            response = input()
            c.execute("DELETE FROM urls WHERE id={}".format(id_))
    db.commit()


def export_csv(out):
    """
    export the database into csv

    out : str
        filename where to write the csv

    Examples:

    bm export out.csv
    """
    df = _export_dataframe()
    df.to_csv(out, index=False)


def _export_dataframe(order_by='views'):
    q = "SELECT id, time, url, title, tags, views FROM urls ORDER BY {}".format(order_by)
    conn = sqlite3.connect(db_path)
    c = conn.cursor()
    rows = []
    for row in c.execute(q):
        rows.append(row)
    cols = ['id', 'time', 'url', 'title',  'tags', 'views']
    df = pd.DataFrame(rows, columns=cols)
    return df


def export_html(out, *, order_by='views'):
    df = _export_dataframe(order_by=order_by)
    df['url'] = df['url'].apply(to_link)
    df['time'] = pd.to_datetime(df['time']).apply(to_date)
    df = df.sort_values(by='time', ascending=False)
    content = df.to_html(
        index=False, 
        escape=False,
        col_space=100,
    )
    html = ("""
    <!doctype html>
    <html>
    <head>
    <meta charset="UTF-8">
    </head>
    {}
    </html>
    """.format(content))
    with open(out, 'w') as fd:
        fd.write(html)



def to_date(time):
    return time.date()


def to_link(url):
    return '<a href="{url}">{url}</a>'.format(url=url)

def tags():
    """
    list of available tags
    """
    q = "SELECT tags FROM urls"
    conn = sqlite3.connect(db_path)
    c = conn.cursor()
    tags = []
    for tag, in c.execute(q):
        tag = tag.split(' ')
        tags.extend(tag)
    tags = sorted(list(set(tags)))
    for t in tags:
        print(t)


def tag(q='', *, id=-1, mode='and'):
    """
    override the tags of urls

    q : str
        keywords to search for separated by space
    id : int
        id of a specific url to tag

    Examples:

    bm tag

    bm tag 'deep learning video'

    bm tag --id=141
    """
    if id < 0:
        keywords = q.split(' ')
        w = _search_request(keywords, mode=mode)
        if q == '':
            q = "SELECT id, url, title FROM urls WHERE tags=''"
        else:
            q = "SELECT id, url, title FROM urls WHERE {}".format(w)
    else:
        q = "SELECT id, url, title FROM urls WHERE id={}".format(id)
    conn = sqlite3.connect(db_path)
    c = conn.cursor()
    for id_, url, title in c.execute(q):
        print(url)
        print(title)
        print('New tag ?', end='')
        tag = input()
        if tag != '':
            conn.execute("UPDATE urls SET tags='{}' WHERE id={}".format(
                tag, id_))
            conn.commit()


def reset_views():
    conn = sqlite3.connect(db_path)
    q = "UPDATE urls SET views = 0"
    c = conn.cursor()
    c.execute(q)
    conn.commit()


def _get_title(url):
    """
    get the title of a web page
    """
    soup = BeautifulSoup(requests.get(url).content, 'lxml')
    if soup.title is None:
        return ''
    return soup.title.text


def _build_where_request(keywords, query_mode='and', fields='all'):
    """
    Get the where part of sql query title or url should
    match any of the keywords

    keywords : list of str
    """
    if fields == 'all':
       fields = 'title,url,description,tags'
    req = [
        field + " LIKE '%{q}%'"
        for field in fields.split(',')
    ]
    req = ' OR '.join(req)
    if query_mode == 'and':
        method = ' AND '
    elif query_mode == 'or':
        method = ' OR '
    else:
        raise ValueError(method)
    search_req = method.join([req.format(q=k) for k in keywords])
    return search_req

def recommand(*, nb=5, id=-1, open=False):
    from functools import partial
    import numpy as np
    from sklearn.feature_extraction.text import TfidfVectorizer
    df = _export_dataframe()
    titles = _get_active_window_titles()
    similarities_list = []
    df['url_title'] = df.apply(lambda d:'{} {}'.format(d['url'], d['title']), axis=1)
    tfidf = TfidfVectorizer().fit(df['url_title'].values.tolist())
    for i, title in enumerate(titles):
        func = partial(similar, tfidf, title)
        df['sim_{}'.format(i)] = df['title'].apply(partial(similar, tfidf, title))
    df['sim'] = df.filter(like='sim_', axis=1).max(axis=1)
    df = df.sort_values(by='sim', ascending=False)
    df = df.iloc[0:nb]
    df['url_full'] = df['url'].copy()
    df['url'] = df['url'].apply(partial(_format, max_length=100))
    cols = df[['id', 'url', 'sim']].to_dict(orient='list')
    print(tabulate(cols, headers='keys'))
    if open:
        import webbrowser
        if id >=0:
            url = df.set_index('id').loc[id]['url_full']
        else:
            url = df.iloc[0]['url_full']
        webbrowser.open(url)

def _get_active_window_titles():
    from subprocess import check_output
    output = check_output('wmctrl -l', shell=True).decode()
    lines = output.split("\n")
    titles = []
    for line in lines:
        line = line.strip()
        if len(line) == 0:
            continue
        _, state, _, *rest = re.split('[ \t]+', line)
        title = ' '.join(rest)
        if state != "-1":
            if ' - ' in title:
                title, *rest = title.split(' - ')
                titles.append(title)
    return titles


def similar(tfidf, a, b):
    import numpy as np
    x = tfidf.transform([a, b])
    x = np.array(x.todense())
    av = x[0]
    bv = x[1]
    eps = 1e-10
    return np.dot(av, bv) / ((np.linalg.norm(av)+eps) * (np.linalg.norm(bv) + eps))


def _tokenize(s):
    return re.split(r'[ \t\./-]+',  s)

if __name__ == '__main__':
    run([a, ls, rm, export_csv, export_html, tag, reset_views, tags, recommand])
